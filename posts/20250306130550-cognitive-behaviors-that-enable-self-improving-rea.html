<!DOCTYPE html>
<html>
<head>
    <title>Cognitive Behaviors That Enable Self-Improving Reasoners - My Automated Blog</title>
    <meta name="description" content="&lt;a href=&quot;https://news.ycombinator.com/item?id=43275193&quot;&gt;Comments&lt;/a&gt;">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../style.css">
    
</head>
<body>
    <header>
        <h1><a href="../index.html">My Automated Blog</a></h1>
        <p>Automatically aggregated content about interesting topics</p>
    </header>
    <main>
        <article>
            <h1>Cognitive Behaviors That Enable Self-Improving Reasoners</h1>
            <div class="meta">Posted on March 06, 2025 | Topics: technology, python, programming</div>
            <div class="content">
                <p>Computer Science &gt; Computation and Language</p>
<p>arXiv:2503.01307</p>
<p>(cs)</p>
<p>[Submitted on 3 Mar 2025]</p>
<p>Title:</p>
<p>Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs</p>
<p>Authors:</p>
<p>Kanishk Gandhi</p>
<p>, </p>
<p>Ayush Chakravarthy</p>
<p>, </p>
<p>Anikait Singh</p>
<p>, </p>
<p>Nathan Lile</p>
<p>, </p>
<p>Noah D. Goodman</p>
<p>View a PDF of the paper titled Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs, by Kanishk Gandhi and 4 other authors</p>
<p>View PDF</p>
<p>HTML (experimental)</p>
<p>Abstract:</p>
<p>Test-time inference has emerged as a powerful paradigm for enabling language models to ``think'' longer and more carefully about complex challenges, much like skilled human experts. While reinforcement learning (RL) can drive self-improvement in language models on verifiable tasks, some models exhibit substantial gains while others quickly plateau. For instance, we find that Qwen-2.5-3B far exceeds Llama-3.2-3B under identical RL training for the game of Countdown. This discrepancy raises a critical question: what intrinsic properties enable effective self-improvement? We introduce a framework to investigate this question by analyzing four key cognitive behaviors -- verification, backtracking, subgoal setting, and backward chaining -- that both expert human problem solvers and successful language models employ. Our study reveals that Qwen naturally exhibits these reasoning behaviors, whereas Llama initially lacks them. In systematic experimentation with controlled behavioral datasets, we find that priming Llama with examples containing these reasoning behaviors enables substantial improvements during RL, matching or exceeding Qwen's performance. Importantly, the presence of reasoning behaviors, rather than correctness of answers, proves to be the critical factor -- models primed with incorrect solutions containing proper reasoning patterns achieve comparable performance to those trained on correct solutions. Finally, leveraging continued pretraining with OpenWebMath data, filtered to amplify reasoning behaviors, enables the Llama model to match Qwen's self-improvement trajectory. Our findings establish a fundamental relationship between initial reasoning behaviors and the capacity for improvement, explaining why some language models effectively utilize additional computation while others plateau.</p>
<p>Subjects:</p>
<p>Computation and Language (cs.CL)</p>
<p>; Machine Learning (cs.LG)</p>
<p>Cite as:</p>
<p>arXiv:2503.01307</p>
<p>[cs.CL]</p>
<p>(or </p>
<p>arXiv:2503.01307v1</p>
<p>[cs.CL]</p>
<p>for this version)</p>
<p>https://doi.org/10.48550/arXiv.2503.01307</p>
<p>Focus to learn more</p>
<pre><code>              arXiv-issued DOI via DataCite
</code></pre>
<p>Submission history</p>
<p>From: Kanishk Gandhi [</p>
<p>view email</p>
<p>]      </p>
<p>[v1]</p>
<pre><code>    Mon, 3 Mar 2025 08:46:22 UTC (2,097 KB)
</code></pre>
<p>Full-text links:</p>
<p>Access Paper:</p>
<p>View a PDF of the paper titled Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs, by Kanishk Gandhi and 4 other authors</p>
<p>View PDF</p>
<p>HTML (experimental)</p>
<p>TeX Source</p>
<p>Other Formats</p>
<p>view license</p>
<pre><code>Current browse context:
</code></pre>
<p>cs.CL</p>
<p>&lt; prev</p>
<p>|  </p>
<p>next &gt;</p>
<p>new</p>
<p>| </p>
<p>recent</p>
<p>| </p>
<p>2025-03</p>
<pre><code>Change to browse by:
</code></pre>
<p>cs</p>
<p>cs.LG</p>
<p>References &amp; Citations</p>
<p>NASA ADS</p>
<p>Google Scholar</p>
<p>Semantic Scholar</p>
<p>a</p>
<p>export BibTeX citation</p>
<p>Loading...</p>
<p>BibTeX formatted citation</p>
<p>×</p>
<p>loading...</p>
<p>Data provided by: </p>
<p>Bookmark</p>
<p>Bibliographic Tools</p>
<p>Bibliographic and Citation Tools</p>
<p>Bibliographic Explorer Toggle</p>
<p>Bibliographic Explorer</p>
<p>(</p>
<p>What is the Explorer?</p>
<p>)</p>
<p>Connected Papers Toggle</p>
<p>Connected Papers</p>
<p>(</p>
<p>What is Connected Papers?</p>
<p>)</p>
<p>Litmaps Toggle</p>
<p>Litmaps</p>
<p>(</p>
<p>What is Litmaps?</p>
<p>)</p>
<p>scite.ai Toggle</p>
<p>scite Smart Citations</p>
<p>(</p>
<p>What are Smart Citations?</p>
<p>)</p>
<p>Code, Data, Media</p>
<p>Code, Data and Media Associated with this Article</p>
<p>alphaXiv Toggle</p>
<p>alphaXiv</p>
<p>(</p>
<p>What is alphaXiv?</p>
<p>)</p>
<p>Links to Code Toggle</p>
<p>CatalyzeX Code Finder for Papers</p>
<p>(</p>
<p>What is CatalyzeX?</p>
<p>)</p>
<p>DagsHub Toggle</p>
<p>DagsHub</p>
<p>(</p>
<p>What is DagsHub?</p>
<p>)</p>
<p>GotitPub Toggle</p>
<p>Gotit.pub</p>
<p>(</p>
<p>What is GotitPub?</p>
<p>)</p>
<p>Huggingface Toggle</p>
<p>Hugging Face</p>
<p>(</p>
<p>What is Huggingface?</p>
<p>)</p>
<p>Links to Code Toggle</p>
<p>Papers with Code</p>
<p>(</p>
<p>What is Papers with Code?</p>
<p>)</p>
<p>ScienceCast Toggle</p>
<p>ScienceCast</p>
<p>(</p>
<p>What is ScienceCast?</p>
<p>)</p>
<p>Demos</p>
<p>Demos</p>
<p>Replicate Toggle</p>
<p>Replicate</p>
<p>(</p>
<p>What is Replicate?</p>
<p>)</p>
<p>Spaces Toggle</p>
<p>Hugging Face Spaces</p>
<p>(</p>
<p>What is Spaces?</p>
<p>)</p>
<p>Spaces Toggle</p>
<p>TXYZ.AI</p>
<p>(</p>
<p>What is TXYZ.AI?</p>
<p>)</p>
<p>Related Papers</p>
<p>Recommenders and Search Tools</p>
<p>Link to Influence Flower</p>
<p>Influence Flower</p>
<p>(</p>
<p>What are Influence Flowers?</p>
<p>)</p>
<p>Core recommender toggle</p>
<p>CORE Recommender</p>
<p>(</p>
<p>What is CORE?</p>
<p>)</p>
<p>Author</p>
<p>Venue</p>
<p>Institution</p>
<p>Topic</p>
<pre><code>    About arXivLabs
</code></pre>
<p>arXivLabs: experimental projects with community collaborators</p>
<p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>
<p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>
<p>Have an idea for a project that will add value for arXiv's community? </p>
<p>Learn more about arXivLabs</p>
<p>.</p>
<p>Which authors of this paper are endorsers?</p>
<p>|</p>
<p>Disable MathJax</p>
<p>(</p>
<p>What is MathJax?</p>
<p>)</p>
            </div>
            <div class="source">Source: <a href="https://arxiv.org/abs/2503.01307" target="_blank">Hacker News</a></div>
        </article>
        <div class="affiliate">
            
        </div>
    </main>
    <footer>
        <p>&copy; 2025 My Automated Blog. All rights reserved.</p>
    </footer>
</body>
</html>